import streamlit as st
from streamlit_drawable_canvas import st_canvas
import cv2
import numpy as np
import tensorflow as tf
from PIL import Image
import os
import pandas as pd
import math

# ==========================================
#              è¨­å®šèˆ‡æ¨¡å‹è¼‰å…¥
# ==========================================
st.set_page_config(page_title="AI æ‰‹å¯«æ•¸å­—è¾¨è­˜ (V58 Solidity)", page_icon="ğŸ”¢", layout="wide")

MODEL_FILE = "cnn_model_robust.h5"

@st.cache_resource
def load_model():
    if os.path.exists(MODEL_FILE):
        return tf.keras.models.load_model(MODEL_FILE)
    return None

if not os.path.exists(MODEL_FILE):
    st.error(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {MODEL_FILE}")
    st.stop()

cnn_model = load_model()

# ==========================================
#              ç‹€æ…‹ç®¡ç† (è¿½è¹¤å™¨)
# ==========================================
if 'tracker' not in st.session_state:
    st.session_state.tracker = {
        'next_id': 1,       
        'objects': []       
    }

def reset_tracker():
    st.session_state.tracker = {'next_id': 1, 'objects': []}

# ==========================================
#              æ ¸å¿ƒæ¼”ç®—æ³•
# ==========================================
def center_by_moments_cnn(src):
    img = src.copy()
    m = cv2.moments(img, True)
    if m['m00'] < 0.1: return cv2.resize(img, (28, 28))
    cX, cY = m['m10'] / m['m00'], m['m01'] / m['m00']
    tX, tY = 14.0 - cX, 14.0 - cY
    M = np.float32([[1, 0, tX], [0, 1, tY]])
    return cv2.warpAffine(img, M, (28, 28), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=0)

def split_touching_digits(roi_binary):
    h, w = roi_binary.shape
    if w / h < 1.2: return [(0, roi_binary)]
    projection = np.sum(roi_binary, axis=0)
    mid_start, mid_end = int(w * 0.25), int(w * 0.75)
    if mid_end <= mid_start: return [(0, roi_binary)]
    split_x = mid_start + np.argmin(projection[mid_start:mid_end])
    if projection[split_x] > (h * 255 * 0.5): return [(0, roi_binary)]
    part1 = roi_binary[:, :split_x]
    part2 = roi_binary[:, split_x:]
    if part1.shape[1] < 5 or part2.shape[1] < 5: return [(0, roi_binary)]
    return [(0, part1), (split_x, part2)]

def merge_nearby_boxes(boxes, threshold=20):
    if not boxes: return []
    boxes.sort(key=lambda b: b[0])
    merged = []
    current_box = boxes[0] 
    for next_box in boxes[1:]:
        cx, cy, cw, ch = current_box
        nx, ny, nw, nh = next_box
        distance = nx - (cx + cw)
        vertical_overlap = (ny < cy + ch) and (ny + nh > cy)
        if distance < threshold and vertical_overlap:
            new_x = min(cx, nx)
            new_y = min(cy, ny)
            new_w = max(cx + cw, nx + nw) - new_x
            new_h = max(cy + ch, ny + nh) - new_y
            current_box = [new_x, new_y, new_w, new_h]
        else:
            merged.append(current_box)
            current_box = next_box
    merged.append(current_box)
    return merged

def update_tracker(current_boxes_coords):
    tracked_objects = st.session_state.tracker['objects']
    next_id = st.session_state.tracker['next_id']
    new_tracked_objects = []
    assigned_ids = [] 
    final_ids_for_boxes = []

    for box in current_boxes_coords:
        x, y, w, h = box
        cx, cy = x + w/2, y + h/2
        best_match_id = None
        min_dist = 999999
        for old_obj in tracked_objects:
            ox, oy = old_obj['center']
            dist = math.sqrt((cx - ox)**2 + (cy - oy)**2)
            if dist < 50 and old_obj['id'] not in assigned_ids:
                if dist < min_dist:
                    min_dist = dist
                    best_match_id = old_obj['id']
        
        if best_match_id is not None:
            final_id = best_match_id
            assigned_ids.append(final_id)
        else:
            final_id = next_id
            next_id += 1
            
        final_ids_for_boxes.append(final_id)
        new_tracked_objects.append({'id': final_id, 'center': (cx, cy)})
    
    st.session_state.tracker['objects'] = new_tracked_objects
    st.session_state.tracker['next_id'] = next_id
    return final_ids_for_boxes

# [V58] æ–°å¢ï¼šæ‰å¯¦åº¦ (Solidity) èˆ‡ å‡¸åŒ…æª¢æŸ¥
def is_valid_digit_shape(roi_binary, show_debug_info=False):
    contours, hierarchy = cv2.findContours(roi_binary, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    if not contours: return False
    
    # æ‰¾å‡ºæœ€å¤§çš„è¼ªå»“
    c = max(contours, key=cv2.contourArea)
    area = cv2.contourArea(c)
    
    if area < 10: return False # å¤ªå°
    
    # 1. æ‰å¯¦åº¦æª¢æŸ¥ (Solidity)
    hull = cv2.convexHull(c)
    hull_area = cv2.contourArea(hull)
    if hull_area == 0: return False
    solidity = float(area) / hull_area
    
    # ä¸­æ–‡å­—çš„ç­†åŠƒé€šå¸¸å¾ˆæ•£ï¼ŒSolidity æœƒå¾ˆä½
    # æ•¸å­—é€šå¸¸æ¯”è¼ƒé£½æ»¿ï¼ŒSolidity è¼ƒé«˜ (é™¤äº† 1 å’Œ 7 å¯èƒ½è¼ƒä½ï¼Œä½†é€šå¸¸ä¹Ÿåœ¨ 0.25 ä»¥ä¸Š)
    if solidity < 0.25: 
        return False 

    # 2. ç ´æ´æª¢æŸ¥
    holes = 0
    if hierarchy is not None:
        for h in hierarchy[0]:
            if h[3] != -1:
                holes += 1
    if holes > 2: return False 

    # 3. ç·šæ¢è¤‡é›œåº¦ (Crossing Number)
    h, w = roi_binary.shape
    check_rows = [int(h*0.25), int(h*0.5), int(h*0.75)]
    for r in check_rows:
        row_pixels = roi_binary[r, :]
        transitions = 0
        prev_val = 0
        for val in row_pixels:
            if val > 127 and prev_val <= 127:
                transitions += 1
            prev_val = val
        if transitions > 3: return False

    check_cols = [int(w*0.25), int(w*0.5), int(w*0.75)]
    for c in check_cols:
        col_pixels = roi_binary[:, c]
        transitions = 0
        prev_val = 0
        for val in col_pixels:
            if val > 127 and prev_val <= 127:
                transitions += 1
            prev_val = val
        if transitions > 3: return False

    return True

def process_and_predict(image_bgr, min_area, min_density, min_confidence, box_padding, proc_mode, manual_thresh, dilation_iter, use_morph_close, merge_dist, use_tracking, use_strict_filter, show_debug):
    result_img = image_bgr.copy()
    h_img_full, w_img_full = result_img.shape[:2]
    
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)

    if proc_mode == "adaptive":
        binary_proc = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 10)
    elif proc_mode == "manual":
        _, thresh = cv2.threshold(blur, manual_thresh, 255, cv2.THRESH_BINARY_INV)
        binary_proc = thresh
    else: # "otsu"
        if np.mean(gray) > 127:
            flag = cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU
        else:
            flag = cv2.THRESH_BINARY + cv2.THRESH_OTSU
        _, thresh = cv2.threshold(blur, 0, 255, flag)
        binary_proc = thresh

    if use_morph_close:
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        binary_proc = cv2.morphologyEx(binary_proc, cv2.MORPH_CLOSE, kernel, iterations=1)

    if dilation_iter > 0:
        binary_proc = cv2.dilate(binary_proc, None, iterations=dilation_iter)
    
    if show_debug:
        st.image(binary_proc, caption=f"ã€Debugã€‘äºŒå€¼åŒ–å½±åƒ", width=300)
    
    nb, output, stats_cc, _ = cv2.connectedComponentsWithStats(binary_proc, connectivity=8)
    
    raw_boxes = []
    for i in range(1, nb):
        x, y, w, h = stats_cc[i, :4]
        
        # [V58] é‚Šç•Œéæ¿¾ (Border Check)
        # å¦‚æœæ¡†æ¡†è²¼åˆ°åœ–ç‰‡çš„æœ€é‚Šç·£ (èª¤å·® 2 pixel)ï¼Œå¾ˆæœ‰å¯èƒ½æ˜¯åˆ‡å‰²é›œè¨Šæˆ–æ»¿ç‰ˆæ–‡å­—ï¼Œç›´æ¥ä¸Ÿæ‰
        if x <= 2 or y <= 2 or (x + w) >= w_img_full - 2 or (y + h) >= h_img_full - 2:
            continue
            
        # å½¢ç‹€éæ¿¾
        if use_strict_filter:
            aspect_ratio = w / float(h)
            if aspect_ratio > 3.0 or aspect_ratio < 0.1:
                continue

        raw_boxes.append([x, y, w, h])

    if merge_dist > 0:
        processing_boxes = merge_nearby_boxes(raw_boxes, threshold=merge_dist)
    else:
        processing_boxes = raw_boxes

    if not use_tracking:
        processing_boxes.sort(key=lambda b: b[0])

    rois_to_pred = []
    coords_to_draw = []
    valid_boxes = [] 

    for box in processing_boxes:
        x, y, w, h = box
        if w * h < min_area: continue

        sub_roi = binary_proc[y:y+h, x:x+w]
        sh, sw = sub_roi.shape
        if sw == 0 or sh == 0: continue
        
        # [V58] å‘¼å«æ‰å¯¦åº¦æª¢æŸ¥
        if use_strict_filter:
            if not is_valid_digit_shape(sub_roi):
                continue

        n_white_pix = cv2.countNonZero(sub_roi)
        box_area = sw * sh
        density = n_white_pix / float(box_area)

        if n_white_pix < min_area: continue
        if density < min_density: continue
        
        side = max(sw, sh)
        container = np.zeros((side+40, side+40), dtype=np.uint8)
        offset_y, offset_x_c = 20 + (side-sh)//2, 20 + (side-sw)//2
        container[offset_y:offset_y+sh, offset_x_c:offset_x_c+sw] = sub_roi
        
        final_roi = center_by_moments_cnn(cv2.resize(container, (28, 28), interpolation=cv2.INTER_AREA))
        final_roi_norm = np.expand_dims(final_roi.astype('float32') / 255.0, axis=-1)
        
        rois_to_pred.append(final_roi_norm)
        coords_to_draw.append((x, y, w, h))
        valid_boxes.append([x, y, w, h])

    final_ids = []
    if use_tracking:
        final_ids = update_tracker(valid_boxes)
    else:
        final_ids = list(range(1, len(valid_boxes) + 1))

    detected_info = []

    if len(rois_to_pred) > 0:
        predictions = cnn_model.predict(np.array(rois_to_pred), verbose=0)
        
        for i, pred_probs in enumerate(predictions):
            res_id = np.argmax(pred_probs)
            confidence = np.max(pred_probs)
            rx, ry, w, h = coords_to_draw[i]
            
            threshold = min_confidence
            if use_strict_filter:
                threshold = max(0.85, min_confidence)

            if confidence < threshold:
                continue

            current_id = final_ids[i] 

            roi_display = cv2.cvtColor(binary_proc[ry:ry+h, rx:rx+w], cv2.COLOR_GRAY2RGB)
            roi_display = cv2.bitwise_not(roi_display)

            detected_info.append({
                "id": current_id,
                "digit": str(res_id), 
                "confidence": float(confidence),
                "roi_img": roi_display
            })
            
            label = f"#{current_id}"
            pad = box_padding
            p_x1 = max(0, rx - pad)
            p_y1 = max(0, ry - pad)
            p_x2 = min(w_img_full, rx + w + pad)
            p_y2 = min(h_img_full, ry + h + pad)

            cv2.rectangle(result_img, (p_x1, p_y1), (p_x2, p_y2), (0, 255, 0), 2)
            cv2.putText(result_img, label, (p_x1, p_y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
    detected_info.sort(key=lambda x: x['id'])
            
    return result_img, detected_info

# ==========================================
#              Streamlit UI ä»‹é¢
# ==========================================
st.title("ğŸ”¢ AI æ‰‹å¯«è¾¨è­˜ (V58 Solidity)")

st.sidebar.header("ğŸ”§ è¨­å®š")
mode_option = st.sidebar.selectbox("è¼¸å…¥æ¨¡å¼", ("âœï¸ æ‰‹å¯«æ¿", "ğŸ“· æ‹ç…§è¾¨è­˜", "ğŸ“‚ ä¸Šå‚³åœ–ç‰‡"))

if 'last_mode' not in st.session_state:
    st.session_state.last_mode = mode_option
if st.session_state.last_mode != mode_option:
    reset_tracker()
    st.session_state.last_mode = mode_option

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ–¼ï¸ å½±åƒè™•ç†")
proc_mode_sel = st.sidebar.radio(
    "é¸æ“‡æ¼”ç®—æ³•",
    ("otsu", "adaptive", "manual"),
    format_func=lambda x: {
        "otsu": "æ¨™æº–æ¨¡å¼ (é©åˆç´”é»‘æ‰‹å¯«æ¿)",
        "adaptive": "ğŸ“„ æ‹ç…§æ¨¡å¼ (æŠ—é™°å½±)",
        "manual": "ğŸšï¸ æ‰‹å‹•é–€æª»"
    }[x],
    index=1 if mode_option != "âœï¸ æ‰‹å¯«æ¿" else 0
)
if proc_mode_sel == "manual":
    manual_thresh = st.sidebar.slider("äºŒå€¼åŒ–é–€æª»", 0, 255, 127)
else:
    manual_thresh = 127

box_padding = st.sidebar.slider("ğŸ–¼ï¸ æ¡†æ¡†ç•™ç™½", 0, 30, 10)
dilation_iter = st.sidebar.slider("ğŸ¡ ç­†ç•«è†¨è„¹ (è®Šç²—)", 0, 3, 2)
use_morph_close = st.sidebar.checkbox("ğŸ©¹ å•Ÿç”¨æ–·ç­†ä¿®è£œ", value=True)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ§² é€²éšä¿®å¾©")
enable_merge = st.sidebar.checkbox("å•Ÿç”¨æ–·å­—åˆä½µ", value=False)
merge_dist = 0
if enable_merge:
    merge_dist = st.sidebar.slider("åˆä½µè·é›¢ (åƒç´ )", 5, 50, 20)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ›¡ï¸ éæ¿¾è¨­å®š")
use_strict_filter = st.sidebar.checkbox("ğŸ›¡ï¸ åš´æ ¼éæ¿¾éæ•¸å­—", value=True, help="ã€å¼·çƒˆå»ºè­°é–‹å•Ÿã€‘ä½¿ç”¨å¹¾ä½•æ‰å¯¦åº¦èˆ‡ç ´æ´æª¢æŸ¥ï¼Œå°ˆé–€éæ¿¾ä¸­æ–‡å­—èˆ‡è¤‡é›œèƒŒæ™¯ã€‚")

min_confidence = st.sidebar.slider("ä¿¡å¿ƒéæ¿¾å™¨", 0.0, 1.0, 0.40) 

st.sidebar.subheader("ğŸ›ï¸ éˆæ•åº¦ (é‡è¦)")
min_area = st.sidebar.slider("æœ€å°é¢ç© (æ•¸å­—ä¸è¦‹èª¿é€™è£¡)", 10, 500, 100) # [V58] é è¨­èª¿é«˜åˆ° 100ï¼Œé¿å…æŠ“åˆ°æ¢—åœ–è£¡çš„å°é›œé»
min_density = st.sidebar.slider("æœ€å°å¯†åº¦", 0.05, 0.3, 0.05)
show_debug = st.sidebar.checkbox("ğŸ‘ï¸ é¡¯ç¤º Debug è³‡è¨Š", value=False)

def run_app(source_image, use_tracking=False):
    result_img, info_list = process_and_predict(
        source_image, min_area, min_density, min_confidence, box_padding, 
        proc_mode_sel, manual_thresh, dilation_iter, use_morph_close, merge_dist, 
        use_tracking, use_strict_filter, show_debug
    )
    
    c1, c2 = st.columns([3, 2])
    
    with c1:
        st.image(result_img, channels="BGR", use_container_width=True, caption="è¾¨è­˜çµæœ")
    
    with c2:
        if info_list:
            st.success(f"âœ… æ‰¾åˆ° {len(info_list)} å€‹æ•¸å­—")
            if use_tracking:
                if st.button("ğŸ”„ æ¸…é™¤ç·¨è™Ÿè¨˜æ†¶ (Reset ID)"):
                    reset_tracker()
                    st.rerun()

            st.markdown("### è©³ç´°çµæœ")
            with st.container(height=500):
                for item in info_list:
                    cols = st.columns([1, 1, 2])
                    with cols[0]:
                        st.caption(f"#{item['id']}")
                        st.image(item['roi_img'], width=50)
                    with cols[1]:
                        st.metric("æ•¸å­—", item['digit'])
                    with cols[2]:
                        conf = item['confidence']
                        st.caption(f"ä¿¡å¿ƒ: {int(conf*100)}%")
                        st.progress(conf)
                    st.divider()
        else:
            if use_strict_filter:
                st.warning("âš ï¸ æœªç™¼ç¾æ•¸å­— (å·²éæ¿¾é›œè¨Š)")
                st.info("ç³»çµ±åµæ¸¬åˆ°ç•«é¢å¤ªè¤‡é›œï¼ˆå¯èƒ½æ˜¯ä¸­æ–‡æˆ–æ¢—åœ–ï¼‰ï¼Œå·²è‡ªå‹•å¿½ç•¥ã€‚")
            else:
                st.warning("âš ï¸ ç•«é¢ä¸­æœªç™¼ç¾æ•¸å­—ï¼")

# ä»‹é¢æ¸²æŸ“
if mode_option == "âœï¸ æ‰‹å¯«æ¿":
    st.info("ğŸ’¡ åœ¨æ‰‹å¯«æ¿æ¨¡å¼ä¸‹ï¼Œç³»çµ±æœƒä¾ç…§ä½ å¯«çš„é †åºç·¨è™Ÿï¼")
    canvas_result = st_canvas(
        fill_color="rgba(255, 165, 0, 0.3)", 
        stroke_width=20, 
        stroke_color="#FFFFFF", 
        background_color="#000000", 
        height=300, 
        width=600, 
        drawing_mode="freedraw", 
        key="canvas",
        update_streamlit=True
    )
    
    if canvas_result.image_data is not None:
        if np.max(canvas_result.image_data) > 0:
            img_data = canvas_result.image_data.astype(np.uint8)
            img_bgr = cv2.cvtColor(img_data, cv2.COLOR_RGBA2BGR)
            run_app(img_bgr, use_tracking=True)
        else:
            reset_tracker()
            st.info("è«‹åœ¨ç•«å¸ƒä¸Šå¯«å­—...")

elif mode_option in ["ğŸ“· æ‹ç…§è¾¨è­˜", "ğŸ“‚ ä¸Šå‚³åœ–ç‰‡"]:
    if mode_option == "ğŸ“· æ‹ç…§è¾¨è­˜":
        file = st.camera_input("æ‹ç…§")
    else:
        file = st.file_uploader("é¸æ“‡åœ–ç‰‡", type=["jpg", "png"])
        
    if file:
        bytes_data = file.getvalue()
        cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)
        if mode_option == "ğŸ“‚ ä¸Šå‚³åœ–ç‰‡": 
            st.image(cv2_img, caption="åŸå§‹åœ–", width=200, channels="BGR")
        
        run_app(cv2_img, use_tracking=False)
