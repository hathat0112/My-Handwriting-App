import streamlit as st
import cv2
import numpy as np
import os
import time
import av
import joblib
from streamlit_drawable_canvas import st_canvas
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
from streamlit_image_coordinates import streamlit_image_coordinates
from tensorflow.keras.models import load_model
from tensorflow.keras.datasets import mnist
from sklearn.neighbors import KNeighborsClassifier

# è¨­å®šé é¢
st.set_page_config(page_title="AI æ‰‹å¯«è¾¨è­˜ (V65 Ultimate)", page_icon="ğŸ”¢", layout="wide")
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# ==========================================
# 1. å…±ç”¨æ ¸å¿ƒ (Shared Core) - æ‰€æœ‰æ¨¡å¼é€šç”¨
# ==========================================
@st.cache_resource
def load_models():
    """è¼‰å…¥ CNN ä¸»æ¨¡å‹èˆ‡ KNN è¼”åŠ©æ¨¡å‹"""
    cnn = None
    # å˜—è©¦è¼‰å…¥å¤šç¨®å¯èƒ½çš„æ¨¡å‹æª”å
    model_files = ["cnn_model_robust.h5", "mnist_cnn.h5", "cnn_model.h5"]
    for f in model_files:
        if os.path.exists(f):
            try:
                cnn = load_model(f)
                print(f"âœ… CNN æ¨¡å‹è¼‰å…¥æˆåŠŸ: {f}")
                break
            except: pass
    
    knn = None
    knn_path = "knn_model.pkl"
    if os.path.exists(knn_path):
        try:
            knn = joblib.load(knn_path)
        except: pass
    
    # è‹¥ç„¡ KNN å‰‡ç¾å ´è¨“ç·´ä¸€å€‹ç°¡å–®çš„
    if knn is None:
        try:
            (x_train, y_train), _ = mnist.load_data()
            x_flat = x_train.reshape(-1, 784) / 255.0
            knn = KNeighborsClassifier(n_neighbors=3)
            knn.fit(x_flat[:5000], y_train[:5000]) # åƒ…ç”¨ 5000 ç­†åŠ é€Ÿ
            joblib.dump(knn, knn_path)
        except: pass
        
    return cnn, knn

# åˆå§‹åŒ–æ¨¡å‹
cnn_model, knn_model = load_models()

def v65_morphology(binary_img, erosion, dilation):
    """
    [V65 æ ¸å¿ƒ] å½¢æ…‹å­¸è™•ç†ï¼šå…ˆåˆ‡å‰²(Erosion)å†è†¨è„¹(Dilation)
    ä¾†è‡ª app (1).py çš„æ‰‹è¡“åˆ€åŠŸèƒ½
    """
    res = binary_img.copy()
    
    # 1. æ‰‹è¡“åˆ€åˆ‡å‰² (Erosion)ï¼šæŠŠé»åœ¨ä¸€èµ·çš„åˆ‡é–‹
    if erosion > 0:
        kernel = np.ones((3,3), np.uint8)
        res = cv2.erode(res, kernel, iterations=erosion)

    # 2. æ–·ç­†ä¿®è£œ (Close)
    kernel_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    res = cv2.morphologyEx(res, cv2.MORPH_CLOSE, kernel_rect, iterations=1)

    # 3. ç­†ç•«åŠ ç²— (Dilation)
    if dilation > 0:
        res = cv2.dilate(res, None, iterations=dilation)
        
    return res

def center_by_moments(img):
    """å½±åƒé‡å¿ƒç½®ä¸­ (æå‡ MNIST æº–ç¢ºåº¦é—œéµ)"""
    m = cv2.moments(img, True)
    if m['m00'] < 0.1: return cv2.resize(img, (28, 28))
    cX, cY = m['m10'] / m['m00'], m['m01'] / m['m00']
    tX, tY = 14.0 - cX, 14.0 - cY
    M = np.float32([[1, 0, tX], [0, 1, tY]])
    return cv2.warpAffine(img, M, (28, 28), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=0)

def preprocess_input(roi):
    """å°‡è£åˆ‡ä¸‹ä¾†çš„ ROI è½‰ç‚ºæ¨¡å‹å¯è®€æ ¼å¼ (1, 28, 28, 1)"""
    h, w = roi.shape
    # ä¿æŒæ¯”ä¾‹ç¸®æ”¾
    scale = 20.0 / max(h, w)
    nh, nw = max(1, int(h * scale)), max(1, int(w * scale))
    resized = cv2.resize(roi, (nw, nh), interpolation=cv2.INTER_AREA)
    
    # è²¼åˆ° 28x28 ç•«å¸ƒ
    canvas = np.zeros((28, 28), dtype=np.uint8)
    y_off, x_off = (28 - nh) // 2, (28 - nw) // 2
    canvas[y_off:y_off+nh, x_off:x_off+nw] = resized
    
    # é‡å¿ƒç½®ä¸­èˆ‡æ­£è¦åŒ–
    final = center_by_moments(canvas)
    return final.reshape(1, 28, 28, 1).astype('float32') / 255.0

# ==========================================
# 2. æ¨¡å¼ A: é¡é ­æ¨¡å¼å°ˆç”¨é‚è¼¯ (Live Camera)
# çµåˆ app.py çš„ç©©å®šåµæ¸¬ + app (1).py çš„å½¢æ…‹å­¸
# ==========================================
class LiveProcessor(VideoProcessorBase):
    def __init__(self):
        self.model = cnn_model
        self.knn = knn_model
        self.erosion = 0    # é è¨­å€¼ï¼Œæœƒç”± update_params æ›´æ–°
        self.dilation = 2
        self.min_conf = 0.6
        
        # ç©©å®šåº¦èˆ‡æŠ“æ‹è®Šæ•¸ (ä¾†è‡ª app.py)
        self.last_boxes = []
        self.stability_start = None
        self.frozen = False
        self.frozen_frame = None
        self.ui_results = []
        
    def update_params(self, ero, dil, conf):
        self.erosion = ero
        self.dilation = dil
        self.min_conf = conf

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        if self.frozen and self.frozen_frame is not None:
             return av.VideoFrame.from_ndarray(self.frozen_frame, format="bgr24")

        # 1. å‰è™•ç† (Adaptive Threshold é©åˆé¡é ­)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        binary = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 10)
        
        # [V65 Feature] å½¢æ…‹å­¸è™•ç†
        binary_proc = v65_morphology(binary, self.erosion, self.dilation)
        
        # 2. è¼ªå»“åµæ¸¬
        cnts, _ = cv2.findContours(binary_proc, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        current_boxes = []
        
        for c in cnts:
            if cv2.contourArea(c) < 100: continue
            x, y, w, h = cv2.boundingRect(c)
            if x<5 or y<5: continue # é‚Šç·£éæ¿¾
            
            # é æ¸¬
            roi = binary_proc[y:y+h, x:x+w]
            inp = preprocess_input(roi)
            if self.model:
                pred = self.model.predict(inp, verbose=0)[0]
                conf = np.max(pred)
                lbl = np.argmax(pred)
                
                if conf > self.min_conf:
                    current_boxes.append({'rect':(x,y,w,h), 'lbl':lbl, 'conf':conf})
                    # ç¹ªåœ–
                    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)
                    cv2.putText(img, f"{lbl}", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

        # 3. ç°¡å–®çš„ç©©å®šåº¦é‚è¼¯ (ç°¡åŒ–ç‰ˆ)
        return av.VideoFrame.from_ndarray(img, format="bgr24")

def run_camera_mode(erosion, dilation, min_conf):
    st.info("ğŸ“· å°‡æ•¸å­—ç½®æ–¼é¡é ­ä¸­å¤®ï¼Œç³»çµ±æœƒè‡ªå‹•è¾¨è­˜")
    ctx = webrtc_streamer(
        key="v65-cam",
        mode=WebRtcMode.SENDRECV,
        video_processor_factory=LiveProcessor,
        async_processing=True,
    )
    if ctx.video_processor:
        ctx.video_processor.update_params(erosion, dilation, min_conf)

# ==========================================
# 3. æ¨¡å¼ B: æ‰‹å¯«æ¿å°ˆç”¨é‚è¼¯ (Canvas)
# ==========================================
def run_canvas_mode(erosion, dilation, min_conf):
    c1, c2 = st.columns([2, 1])
    with c1:
        canvas_res = st_canvas(
            fill_color="rgba(255, 165, 0, 0.3)",
            stroke_width=20,
            stroke_color="#FFF",
            background_color="#000",
            height=350,
            width=600,
            drawing_mode="freedraw",
            key="canvas_v65"
        )
    
    with c2:
        st.markdown("### ğŸ‘ï¸ è¾¨è­˜çµæœ")
        if canvas_res.image_data is not None and np.max(canvas_res.image_data) > 0:
            # è½‰æ›å½±åƒ
            raw = canvas_res.image_data.astype(np.uint8)
            img_bgr = cv2.cvtColor(raw, cv2.COLOR_RGBA2BGR) if raw.shape[2] == 4 else raw
            gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
            
            # æ‰‹å¯«æ¿é©åˆ Otsu
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # [V65 Feature] å½¢æ…‹å­¸è™•ç†
            processed = v65_morphology(binary, erosion, dilation)
            
            # é¡¯ç¤ºè™•ç†å¾Œå½±åƒ (Debug)
            st.image(processed, caption="AI çœ‹è¦‹çš„å½±åƒ (ç¶“åˆ‡å‰²è™•ç†)", width=200)
            
            # åµæ¸¬èˆ‡è¾¨è­˜
            cnts, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            # æ’åº
            boxes = sorted([cv2.boundingRect(c) for c in cnts if cv2.contourArea(c) > 50], key=lambda b: b[0])
            
            results_txt = []
            for i, (x, y, w, h) in enumerate(boxes):
                roi = processed[y:y+h, x:x+w]
                inp = preprocess_input(roi)
                
                pred = cnn_model.predict(inp, verbose=0)[0]
                conf = np.max(pred)
                lbl = np.argmax(pred)
                
                if conf > min_conf:
                    results_txt.append(f"**#{i+1}**: æ•¸å­— `{lbl}` ({int(conf*100)}%)")
            
            if results_txt:
                for r in results_txt: st.markdown(r)
            else:
                st.warning("å¯«å¾—å¤ªæ½¦è‰æˆ–ä¿¡å¿ƒéä½")

# ==========================================
# 4. æ¨¡å¼ C: ä¸Šå‚³åœ–ç‰‡å°ˆç”¨é‚è¼¯ (Upload)
# çµåˆ app.py çš„ç·¨è¼¯æ¨¡å¼ (Edit Mode) èˆ‡ é˜²å‘†æ©Ÿåˆ¶
# ==========================================
def run_upload_mode(erosion, dilation, min_conf):
    st.info("æ”¯æ´ JPG/PNGï¼Œå¯åˆ‡æ›è‡³ã€Œç·¨è¼¯æ¨¡å¼ã€ä¿®æ­£èª¤åˆ¤")
    
    file = st.file_uploader("é¸æ“‡åœ–ç‰‡", type=["jpg", "png", "jpeg"])
    edit_mode = st.toggle("ğŸ”§ å•Ÿç”¨ç·¨è¼¯æ¨¡å¼ (é»æ“Šåˆªé™¤/æ–°å¢)", value=False)
    
    if 'ignored_boxes' not in st.session_state: st.session_state.ignored_boxes = set()
    if 'manual_boxes' not in st.session_state: st.session_state.manual_boxes = []
    
    # æ›åœ–ç‰‡æ™‚é‡ç½®
    if file and st.session_state.get('last_file') != file.name:
        st.session_state.ignored_boxes = set()
        st.session_state.manual_boxes = []
        st.session_state.last_file = file.name

    if file:
        file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
        img_origin = cv2.imdecode(file_bytes, 1)
        
        # å‰è™•ç†
        gray = cv2.cvtColor(img_origin, cv2.COLOR_BGR2GRAY)
        # è‡ªå‹•åˆ¤æ–·æ¨¡å¼ï¼šç…§ç‰‡ç”¨ Adaptive, æˆªåœ–ç”¨ Otsu
        is_photo = np.mean(gray) < 240 and np.std(gray) > 30
        if is_photo:
            binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 10)
        else:
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
            
        # [V65 Feature]
        processed = v65_morphology(binary, erosion, dilation)
        
        # åµæ¸¬
        cnts, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        detected_data = []
        
        display_img = img_origin.copy()
        
        # è‡ªå‹•æ¡†
        for c in cnts:
            if cv2.contourArea(c) < 50: continue
            x, y, w, h = cv2.boundingRect(c)
            
            # ==========================================
            # ğŸ›‘ å¼·åŒ–ç‰ˆé˜²å‘†éæ¿¾ (Stricter Filtering)
            # ==========================================
            aspect_ratio = w / float(h)
            
            # 1. åš´æ ¼é•·å¯¬æ¯”ï¼šæ•¸å­—é€šå¸¸æ˜¯ç˜¦çš„ï¼Œæ­£æ–¹å½¢(1.0)æˆ–æ©«å‘(>1.0)é€šå¸¸æ˜¯ä¸­æ–‡å­—æˆ–èƒŒæ™¯
            if aspect_ratio > 0.9: 
                continue 
            
            # 2. é‚Šæ¡†å¤§å°éæ¿¾ï¼šéå¤§çš„æ¡†é€šå¸¸æ˜¯èƒŒæ™¯ (è¶…é5%)
            img_area = img_origin.shape[0] * img_origin.shape[1]
            if w * h > (img_area * 0.05): 
                continue 
            
            # 3. å¯†åº¦éæ¿¾ï¼šæ•¸å­—ç­†ç•«ç´°ï¼Œè‹¥å¯†åº¦éé«˜(>0.65)é€šå¸¸æ˜¯è‰²å¡Š
            roi_check = binary[y:y+h, x:x+w]
            density = cv2.countNonZero(roi_check) / (w * h)
            if density > 0.65: 
                continue 
            # ==========================================

            bid = f"{x}_{y}_{w}_{h}"
            
            if bid in st.session_state.ignored_boxes:
                cv2.rectangle(display_img, (x,y), (x+w,y+h), (128,128,128), 1)
                continue
            
            roi = processed[y:y+h, x:x+w]
            inp = preprocess_input(roi)
            pred = cnn_model.predict(inp, verbose=0)[0]
            
            if np.max(pred) > min_conf:
                lbl = np.argmax(pred)
                cv2.rectangle(display_img, (x,y), (x+w,y+h), (0,255,0), 2)
                cv2.putText(display_img, str(lbl), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 2)
                detected_data.append({'id': bid, 'rect':(x,y,w,h), 'type':'auto'})

        # æ‰‹å‹•æ¡†
        for mbox in st.session_state.manual_boxes:
            mx, my, mw, mh = mbox['rect']
            cv2.rectangle(display_img, (mx,my), (mx+mw,my+mh), (255,0,255), 2)
            cv2.putText(display_img, str(mbox['lbl']), (mx, my-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,0,255), 2)
            detected_data.append({'id': 'manual', 'rect':(mx,my,mw,mh), 'type':'manual'})

        # é¡¯ç¤º
        # è½‰æ›ç‚º RGB
        img_rgb = cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB)
        
        if edit_mode:
            st.warning("é»æ“Šç¶ æ¡†å¯åˆªé™¤ï¼›é»æ“Šæœªåµæ¸¬åˆ°çš„é»‘å­—å¯æ–°å¢")
            value = streamlit_image_coordinates(img_rgb, key="click_upload")
            
            if value:
                cx, cy = value['x'], value['y']
                hit = False
                # åˆªé™¤é‚è¼¯
                for item in detected_data:
                    if item['type'] == 'manual': continue # ç°¡åŒ–ï¼šæ‰‹å‹•æ¡†å…ˆä¸åˆª
                    rx, ry, rw, rh = item['rect']
                    if rx < cx < rx+rw and ry < cy < ry+rh:
                        st.session_state.ignored_boxes.add(item['id'])
                        hit = True; st.rerun(); break
                
                # æ–°å¢é‚è¼¯
                if not hit:
                    # åœ¨ processed æ‰¾é»æ“Šçš„è¼ªå»“
                    mcnts, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    for mc in mcnts:
                        if cv2.pointPolygonTest(mc, (cx, cy), False) >= 0:
                            mx, my, mw, mh = cv2.boundingRect(mc)
                            m_roi = processed[my:my+mh, mx:mx+mw]
                            m_pred = cnn_model.predict(preprocess_input(m_roi), verbose=0)[0]
                            st.session_state.manual_boxes.append({'rect':(mx,my,mw,mh), 'lbl':np.argmax(m_pred)})
                            st.rerun(); break
        else:
            st.image(img_rgb, use_container_width=True)
            st.markdown(f"**å…±æ‰¾åˆ° {len(detected_data)} å€‹æ•¸å­—**")

# ==========================================
# 5. ä¸»ç¨‹å¼åˆ†æµ (Main Dispatcher)
# ==========================================
def main():
    st.sidebar.title("ğŸ”¢ æ‰‹å¯«è¾¨è­˜ V65 Ultimate")
    mode = st.sidebar.radio("é¸æ“‡æ¨¡å¼", ["ğŸ“· é¡é ­ (Live)", "âœï¸ æ‰‹å¯«æ¿ (Canvas)", "ğŸ“‚ ä¸Šå‚³åœ–ç‰‡ (Upload)"])
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ”ª V65 æ‰‹è¡“åˆ€åƒæ•¸")
    erosion_iter = st.sidebar.slider("åˆ‡å‰²æ²¾é» (Erosion)", 0, 5, 0, help="æ•¸å­—é»åœ¨ä¸€èµ·æ™‚èª¿å¤§é€™å€‹")
    dilation_iter = st.sidebar.slider("ç­†ç•«åŠ ç²— (Dilation)", 0, 3, 2, help="ç­†ç•«å¤ªç´°æ™‚èª¿å¤§é€™å€‹")
    min_conf = st.sidebar.slider("ä¿¡å¿ƒé–€æª»", 0.0, 1.0, 0.5)

    if cnn_model is None:
        st.error("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ (cnn_model_robust.h5 æˆ– mnist_cnn.h5)")
        st.stop()

    if mode == "ğŸ“· é¡é ­ (Live)":
        run_camera_mode(erosion_iter, dilation_iter, min_conf)
    elif mode == "âœï¸ æ‰‹å¯«æ¿ (Canvas)":
        run_canvas_mode(erosion_iter, dilation_iter, min_conf)
    elif mode == "ğŸ“‚ ä¸Šå‚³åœ–ç‰‡ (Upload)":
        run_upload_mode(erosion_iter, dilation_iter, min_conf)

if __name__ == "__main__":
    main()
