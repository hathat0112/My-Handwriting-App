# ==========================================
# 4. æ¨¡å¼ C: ä¸Šå‚³åœ–ç‰‡å°ˆç”¨é‚è¼¯ (Upload) - å¼·åŒ–æº–ç¢ºç‰ˆ
# ==========================================
def run_upload_mode(erosion, dilation, min_conf):
    st.info("æ”¯æ´ JPG/PNGï¼Œç³»çµ±æœƒè‡ªå‹•æ¡†é¸æ•¸å­—")
    
    file = st.file_uploader("é¸æ“‡åœ–ç‰‡", type=["jpg", "png", "jpeg"])
    
    if file:
        file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
        img_origin = cv2.imdecode(file_bytes, 1)
        h_orig, w_orig = img_origin.shape[:2]
        
        # 1. å½±åƒå¢å¼· (Contrast Enhancement)
        # å¢åŠ å°æ¯”åº¦ï¼Œè®“æ–‡å­—æ›´é»‘ï¼ŒèƒŒæ™¯æ›´äº®
        lab = cv2.cvtColor(img_origin, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        cl = clahe.apply(l)
        limg = cv2.merge((cl,a,b))
        enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
        
        gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)
        
        # 2. é›™é‡äºŒå€¼åŒ–ç­–ç•¥ (Dual Thresholding)
        # Aè¨ˆç•«: è‡ªé©æ‡‰é–¾å€¼ (æŠ“ç´°ç¯€)
        thresh_adapt = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 25, 15)
        # Bè¨ˆç•«: Otsu é–¾å€¼ (æŠ“ä¸»é«”)
        _, thresh_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # å–äº¤é›†ï¼šåªæœ‰å…©å€‹æ–¹æ³•éƒ½èªç‚ºæ˜¯é»‘å­—çš„åœ°æ–¹æ‰ä¿ç•™ (å¤§å¹…æ¸›å°‘é›œè¨Š)
        binary_combined = cv2.bitwise_and(thresh_adapt, thresh_otsu)
        
        # V65 å½¢æ…‹å­¸æ¸…ç†
        processed = v65_morphology(binary_combined, erosion, dilation)
        
        cnts, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        detected_count = 0
        display_img = img_origin.copy()
        
        for c in cnts:
            area = cv2.contourArea(c)
            if area < 80: continue # æ¿¾é™¤å¤ªå°çš„é›œé»
            x, y, w, h = cv2.boundingRect(c)
            
            # ==========================================
            # ğŸ›‘ æº–ç¢ºåº¦å„ªåŒ–éæ¿¾å™¨ (Accuracy Filters)
            # ==========================================
            
            # 1. é‚Šç·£éæ¿¾ï¼šå»é™¤è²¼åœ¨åœ–ç‰‡é‚Šé‚Šçš„é›œè¨Š
            if x < 5 or y < 5 or (x+w) > w_orig-5 or (y+h) > h_orig-5:
                continue

            # 2. åš´æ ¼é•·å¯¬æ¯”ï¼šæ•¸å­—å¾ˆé›£å¯¬æ–¼ 1.1 å€ (é™¤éæ˜¯æ‰‹å¯«å¾ˆé†œçš„ 2 æˆ– 5)
            aspect_ratio = w / float(h)
            if aspect_ratio > 1.05: # æ¯”ä¹‹å‰æ›´åš´æ ¼ï¼Œç›´æ¥æ¿¾æ‰å¤§éƒ¨åˆ†æ–¹å¡Šä¸­æ–‡å­—
                continue 
            if aspect_ratio < 0.2: # å¤ªç´°é•·é€šå¸¸æ˜¯é›œè¨Šç·šæ¢
                continue

            # 3. å·¨å¤§ç‰©ä»¶éæ¿¾
            if w * h > (h_orig * w_orig * 0.08): 
                continue 

            # 4. ã€é—œéµã€‘åƒç´ å¯†åº¦æª¢æŸ¥ (Pixel Density)
            # æ•¸å­—æ˜¯ç·šæ¢çµ„æˆçš„ï¼Œæ‰€ä»¥é»‘è‰²åƒç´ ä½”æ¯”æ‡‰è©²åœ¨ 20% ~ 55% ä¹‹é–“
            # ä¸­æ–‡å­—ç­†ç•«å¤šï¼Œé€šå¸¸æœƒè¶…é 55%ï¼›å¯¦å¿ƒè‰²å¡Šæœƒæ¥è¿‘ 100%
            roi_check = processed[y:y+h, x:x+w]
            density = cv2.countNonZero(roi_check) / (w * h)
            
            if density < 0.15: continue # å¤ªç©º (å¯èƒ½æ˜¯é›œè¨Šåœˆåœˆ)
            if density > 0.55: continue # å¤ªæ»¿ (é€šå¸¸æ˜¯ä¸­æ–‡å­—æˆ–è‰²å¡Š)
            
            # ==========================================
            
            roi = processed[y:y+h, x:x+w]
            inp = preprocess_input(roi)
            pred = cnn_model.predict(inp, verbose=0)[0]
            
            # å°æ–¼å®¹æ˜“èª¤åˆ¤çš„æ•¸å­— (1, 7)ï¼Œæé«˜é–€æª»
            conf = np.max(pred)
            lbl = np.argmax(pred)
            
            final_conf_thresh = min_conf
            if lbl in [1, 7]: 
                final_conf_thresh += 0.15 # å° 1 å’Œ 7 è¦æ±‚æ›´é«˜ä¿¡å¿ƒ
            
            if conf > final_conf_thresh:
                cv2.rectangle(display_img, (x,y), (x+w,y+h), (0,255,0), 2)
                # åŠ ä¸Šåº•è‰²è®“æ–‡å­—æ›´æ¸…æ¥š
                label_text = f"{lbl}"
                (lw, lh), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)
                cv2.rectangle(display_img, (x, y-lh-10), (x+lw, y), (0,255,0), -1)
                cv2.putText(display_img, label_text, (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,0), 2)
                detected_count += 1

        img_rgb = cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB)
        
        # é¡¯ç¤ºè™•ç†å¾Œçš„é»‘ç™½åœ– (Debugç”¨)ï¼Œè®“ä½¿ç”¨è€…çŸ¥é“ AI åˆ°åº•çœ‹åˆ°ä»€éº¼
        c1, c2 = st.columns([3, 1])
        with c1:
            st.image(img_rgb, use_container_width=True, caption="è¾¨è­˜çµæœ")
        with c2:
            st.image(processed, use_container_width=True, caption="[Debug] AI è¦–è§’ (äºŒå€¼åŒ–)")
            st.markdown(f"**å…±æ‰¾åˆ° {detected_count} å€‹æ•¸å­—**")
