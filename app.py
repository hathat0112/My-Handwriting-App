import streamlit as st
from streamlit_drawable_canvas import st_canvas
import cv2
import numpy as np
import tensorflow as tf
from PIL import Image
import os
import pandas as pd # ç”¨ä¾†åšæ¼‚äº®çš„è¡¨æ ¼

# ==========================================
#              è¨­å®šèˆ‡æ¨¡å‹è¼‰å…¥
# ==========================================
st.set_page_config(page_title="AI æ‰‹å¯«æ•¸å­—è¾¨è­˜ (V34 Full Debug)", page_icon="ğŸ”¢", layout="wide")

MODEL_FILE = "cnn_model_robust.h5"

@st.cache_resource
def load_model():
    if os.path.exists(MODEL_FILE):
        return tf.keras.models.load_model(MODEL_FILE)
    return None

if not os.path.exists(MODEL_FILE):
    st.error(f"æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ: {MODEL_FILE}")
    st.stop()

cnn_model = load_model()

# ==========================================
#              æ ¸å¿ƒæ¼”ç®—æ³•
# ==========================================
def center_by_moments_cnn(src):
    img = src.copy()
    m = cv2.moments(img, True)
    if m['m00'] < 0.1: return cv2.resize(img, (28, 28))
    cX, cY = m['m10'] / m['m00'], m['m01'] / m['m00']
    tX, tY = 14.0 - cX, 14.0 - cY
    M = np.float32([[1, 0, tX], [0, 1, tY]])
    return cv2.warpAffine(img, M, (28, 28), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=0)

def split_touching_digits(roi_binary):
    h, w = roi_binary.shape
    if w / h < 1.2: return [(0, roi_binary)]
    projection = np.sum(roi_binary, axis=0)
    mid_start, mid_end = int(w * 0.25), int(w * 0.75)
    if mid_end <= mid_start: return [(0, roi_binary)]
    split_x = mid_start + np.argmin(projection[mid_start:mid_end])
    if projection[split_x] > (h * 255 * 0.5): return [(0, roi_binary)]
    part1 = roi_binary[:, :split_x]
    part2 = roi_binary[:, split_x:]
    if part1.shape[1] < 5 or part2.shape[1] < 5: return [(0, roi_binary)]
    return [(0, part1), (split_x, part2)]

def analyze_hole_geometry(binary_roi):
    roi_copy = binary_roi.copy()
    contours, hierarchy = cv2.findContours(roi_copy, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    if hierarchy is None: return 0, None
    valid_holes = []
    h_img, w_img = roi_copy.shape
    for i in range(len(contours)):
        if hierarchy[0][i][3] != -1: 
            area = cv2.contourArea(contours[i])
            if area > 15: 
                M = cv2.moments(contours[i])
                if M['m00'] != 0:
                    cy = int(M['m01'] / M['m00'])
                    norm_y = cy / float(h_img)
                    valid_holes.append((area, norm_y))
    if not valid_holes: return 0, None
    valid_holes.sort(key=lambda x: x[0], reverse=True)
    largest_hole_y = valid_holes[0][1]
    return len(valid_holes), largest_hole_y

def process_and_predict(image_bgr, min_area, min_density, min_confidence, show_debug=False):
    """
    V34 æ›´æ–°ï¼šå…¨æ–¹ä½è¨ºæ–·é‚è¼¯
    æœƒç•«å‡ºè¢«éæ¿¾æ‰çš„æ¡†æ¡†ï¼šç´«è‰²(é¢ç©å¤ªå°)ã€è—è‰²(å¯†åº¦å¤ªä½)ã€ç´…è‰²(ä¿¡å¿ƒä¸è¶³)
    """
    result_img = image_bgr.copy()
    
    # 1. è½‰ç°éš & äº®åº¦æª¢æŸ¥
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    max_val = np.max(gray)
    if max_val < 50:
        if show_debug: st.warning(f"âš ï¸ ç•«é¢å¤ªæš— (æœ€é«˜äº®åº¦: {max_val})")
        return result_img, []

    # 2. äºŒå€¼åŒ–
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    binary_proc = cv2.dilate(thresh, None, iterations=1)
    
    if show_debug:
        st.image(binary_proc, caption="ã€Debugã€‘äºŒå€¼åŒ–å½±åƒ (AI çœ¼ä¸­çš„ä¸–ç•Œ)", width=300)
    
    # 3. æŠ“å–ç‰©ä»¶ (æ³¨æ„ï¼šé€™è£¡å…ˆä¸æ¿¾æ‰é¢ç©ï¼Œç‚ºäº†æŠŠå¤ªå°çš„æ¡†ä¹ŸæŠ“å‡ºä¾†ç•«ç´«è‰²æ¡†)
    nb, output, stats_cc, _ = cv2.connectedComponentsWithStats(binary_proc, connectivity=8)
    raw_boxes = sorted([stats_cc[i, :4] for i in range(1, nb)], key=lambda b: b[0])

    rois_to_pred = []
    coords_to_draw = []
    h_img, w_img = binary_proc.shape 

    for box in raw_boxes:
        x, y, w, h = box
        # é‚Šç·£ç§»é™¤
        if x < 5 or y < 5 or (x + w) > w_img - 5 or (y + h) > h_img - 5: continue
        # é«˜åº¦å¤ªæ‰çš„ç›´æ¥å¿½ç•¥ï¼Œé€šå¸¸æ˜¯é›œè¨Šç·šæ¢
        if h < 20: continue 

        # åˆ‡å‰²é€£å­—
        split_results = split_touching_digits(binary_proc[y:y+h, x:x+w])
        
        for offset_x, sub_roi in split_results:
            sh, sw = sub_roi.shape
            if sw == 0 or sh == 0: continue
            
            # --- [è¨ºæ–·é‚è¼¯é–‹å§‹] ---

            # è¨ˆç®—çœŸå¯¦é¢ç©èˆ‡å¯†åº¦
            n_white_pix = cv2.countNonZero(sub_roi)
            box_area = sw * sh
            density = n_white_pix / float(box_area)

            # 1. æª¢æŸ¥é¢ç© (å¤ªå° -> ç´«è‰²æ¡†)
            if n_white_pix < min_area:
                if show_debug:
                    cv2.rectangle(result_img, (x+offset_x, y), (x+offset_x+sw, y+sh), (255, 0, 255), 1) # ç´«è‰²
                    cv2.putText(result_img, "Small", (x+offset_x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 255), 1)
                continue # è·³éï¼Œä¸è¾¨è­˜

            # 2. æª¢æŸ¥å¯†åº¦ (å¤ªä½ -> è—è‰²æ¡†)
            if density < min_density:
                if show_debug:
                    cv2.rectangle(result_img, (x+offset_x, y), (x+offset_x+sw, y+sh), (255, 0, 0), 1) # è—è‰²
                    cv2.putText(result_img, "Noise", (x+offset_x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)
                continue # è·³éï¼Œä¸è¾¨è­˜
            
            # --- [é€šéåŸºæœ¬æª¢æŸ¥ï¼Œæº–å‚™è¾¨è­˜] ---
            
            side = max(sw, sh)
            container = np.zeros((side+40, side+40), dtype=np.uint8)
            offset_y, offset_x_c = 20 + (side-sh)//2, 20 + (side-sw)//2
            container[offset_y:offset_y+sh, offset_x_c:offset_x_c+sw] = sub_roi
            
            final_roi = center_by_moments_cnn(cv2.resize(container, (28, 28), interpolation=cv2.INTER_AREA))
            final_roi_norm = np.expand_dims(final_roi.astype('float32') / 255.0, axis=-1)
            
            rois_to_pred.append(final_roi_norm)
            coords_to_draw.append((x + offset_x, y, sw, sh, sub_roi))

    detected_info = [] # å­˜è©³ç´°è³‡æ–™

    if len(rois_to_pred) > 0:
        predictions = cnn_model.predict(np.array(rois_to_pred), verbose=0)
        
        for i, pred_probs in enumerate(predictions):
            res_id = np.argmax(pred_probs)
            confidence = np.max(pred_probs)
            rx, ry, w, h, roi_original = coords_to_draw[i]
            
            # 3. æª¢æŸ¥ä¿¡å¿ƒ (å¤ªä½ -> ç´…è‰²æ¡†)
            if confidence < min_confidence:
                if show_debug:
                    cv2.rectangle(result_img, (rx, ry), (rx+w, ry+h), (0, 0, 255), 1) # ç´…è‰²
                    label = f"{res_id}? ({int(confidence*100)}%)"
                    cv2.putText(result_img, label, (rx, ry-5), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
                continue

            # --- [è¾¨è­˜æˆåŠŸ] ---
            display_text = str(res_id)
            color = (0, 255, 0) # ç¶ è‰²
            
            # Hybrid é‚è¼¯ä¿®æ­£
            num_holes, hole_y = analyze_hole_geometry(roi_original)
            aspect_ratio = w / float(h)
            pixel_count = cv2.countNonZero(roi_original)
            density = pixel_count / float(w * h)

            if res_id == 6:
                if hole_y is not None and hole_y < 0.58: res_id, display_text, color = 0, "0*", (0, 255, 255)
            elif res_id == 8:
                if num_holes == 1: res_id, display_text, color = 0, "0*", (0, 255, 255)
            elif res_id == 2:
                h_r, w_r = roi_original.shape
                pts = cv2.findNonZero(roi_original[int(h_r*0.7):, :])
                if pts is not None and cv2.boundingRect(pts)[2] < w_r * 0.5:
                    res_id, display_text, color = 7, "7*", (0, 255, 255)
            elif res_id == 7:
                if aspect_ratio < 0.5 or density < 0.25: res_id, display_text, color = 1, "1*", (0, 255, 255)
            elif res_id == 4 or res_id == 9:
                has_hole = (num_holes > 0)
                if res_id == 9 and not has_hole: res_id, display_text, color = 4, "4*", (0, 255, 255)
                elif res_id == 4 and has_hole and confidence < 0.95: res_id, display_text, color = 9, "9*", (0, 255, 255)
            
            # æ ¼å¼åŒ–ä¿¡å¿ƒ (è½‰æˆ %)
            conf_str = f"{int(confidence * 100)}%"
            
            # æ”¶é›†è©³ç´°è³‡è¨Š
            detected_info.append({"æ•¸å­—": str(res_id), "ä¿¡å¿ƒåº¦": conf_str, "ä¿®æ­£": "*" in display_text})
            
            # ç•«åœ–æ™‚åŠ ä¸Šä¿¡å¿ƒåº¦
            label = f"{display_text} ({conf_str})"
            cv2.rectangle(result_img, (rx, ry), (rx+w, ry+h), color, 2)
            cv2.putText(result_img, label, (rx, ry-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
    return result_img, detected_info

# ==========================================
#              Streamlit UI ä»‹é¢
# ==========================================
st.title("ğŸ”¢ AI æ‰‹å¯«è¾¨è­˜ (å«ä¿¡å¿ƒåº¦åˆ†æ)")

st.sidebar.header("ğŸ”§ è¨­å®š")
mode_option = st.sidebar.selectbox("è¼¸å…¥æ¨¡å¼", ("âœï¸ æ‰‹å¯«æ¿", "ğŸ“· æ‹ç…§è¾¨è­˜", "ğŸ“‚ ä¸Šå‚³åœ–ç‰‡"))

# é€™è£¡çš„é¸é …èªªæ˜æ”¹äº†ä¸€ä¸‹ï¼Œå¼·èª¿æœƒé¡¯ç¤ºå¿½ç•¥å€åŸŸ
show_debug = st.sidebar.checkbox("ğŸ‘ï¸ é¡¯ç¤ºäºŒå€¼åŒ–/å¿½ç•¥å€åŸŸ (Debug)", value=False)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ›ï¸ éˆæ•åº¦")
stroke_width = st.sidebar.slider("ç­†åˆ·ç²—ç´°", 5, 30, 20)
min_area = st.sidebar.slider("æœ€å°é¢ç©", 20, 500, 100)
min_density = st.sidebar.slider("æœ€å°å¯†åº¦", 0.05, 0.3, 0.10)

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ¤– AI ä¿¡å¿ƒé–€æª»")
st.sidebar.info("ä¿¡å¿ƒä½æ–¼æ­¤æ•¸å€¼çš„å­—æœƒè¢«å¿½ç•¥")
min_confidence = st.sidebar.slider("ä¿¡å¿ƒéæ¿¾å™¨ (Confidence)", 0.5, 1.0, 0.60) 

if mode_option == "âœï¸ æ‰‹å¯«æ¿":
    st.markdown("### è«‹åœ¨ä¸‹æ–¹å¯«å‡ºä¸€ä¸²æ•¸å­—")
    col1, col2 = st.columns([2, 1])
    
    with col1:
        canvas_result = st_canvas(
            fill_color="rgba(255, 165, 0, 0.3)",
            stroke_width=stroke_width,
            stroke_color="#FFFFFF",
            background_color="#000000",
            height=300,
            width=600,
            drawing_mode="freedraw",
            key="canvas",
        )

    with col2:
        if st.button("é–‹å§‹è¾¨è­˜", type="primary"):
            if canvas_result.image_data is not None:
                img_data = canvas_result.image_data.astype(np.uint8)
                img_bgr = cv2.cvtColor(img_data, cv2.COLOR_RGBA2BGR)
                result_img, info_list = process_and_predict(img_bgr, min_area, min_density, min_confidence, show_debug)
                
                st.image(result_img, channels="BGR", use_container_width=True)
                
                if info_list:
                    st.success("âœ… è¾¨è­˜å®Œæˆï¼")
                    nums_str = " ".join([item["æ•¸å­—"] for item in info_list])
                    st.metric(label="åµæ¸¬çµæœ", value=nums_str)
                    
                    st.markdown("##### ğŸ“Š è©³ç´°æ•¸æ“šåˆ†æ")
                    df = pd.DataFrame(info_list)
                    st.dataframe(df, use_container_width=True)
                else:
                    st.warning("âš ï¸ æœªåµæ¸¬åˆ°æ•¸å­— (æˆ–ä¿¡å¿ƒä¸è¶³ï¼Œè«‹é–‹å•Ÿ Debug æª¢æŸ¥)")

elif mode_option == "ğŸ“· æ‹ç…§è¾¨è­˜":
    img_file = st.camera_input("æ‹ç…§")
    if img_file:
        bytes_data = img_file.getvalue()
        cv2_img = cv2.imdecode(np.frombuffer(bytes_data, np.uint8), cv2.IMREAD_COLOR)
        result_img, info_list = process_and_predict(cv2_img, min_area, min_density, min_confidence, show_debug)
        
        st.image(result_img, channels="BGR")
        if info_list:
             nums_str = " ".join([item["æ•¸å­—"] for item in info_list])
             st.metric(label="åµæ¸¬çµæœ", value=nums_str)
             
             st.markdown("##### ğŸ“Š è©³ç´°æ•¸æ“šåˆ†æ")
             st.dataframe(pd.DataFrame(info_list), use_container_width=True)
        else:
             st.error("ç„¡æ³•è¾¨è­˜ (ä¿¡å¿ƒä¸è¶³ï¼Œè«‹é–‹å•Ÿ Debug æª¢æŸ¥)")

elif mode_option == "ğŸ“‚ ä¸Šå‚³åœ–ç‰‡":
    uploaded_file = st.file_uploader("é¸æ“‡åœ–ç‰‡", type=["jpg", "png"])
    if uploaded_file:
        image = Image.open(uploaded_file)
        img_array = np.array(image)
        if img_array.shape[-1] == 3: img_bgr = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
        else: img_bgr = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)
        st.image(img_array, caption="åŸå§‹åœ–", width=300)
        
        if st.button("è¾¨è­˜"):
            result_img, info_list = process_and_predict(img_bgr, min_area, min_density, min_confidence, show_debug)
            st.image(result_img, channels="BGR")
            if info_list:
                nums_str = " ".join([item["æ•¸å­—"] for item in info_list])
                st.metric(label="åµæ¸¬çµæœ", value=nums_str)
                st.markdown("##### ğŸ“Š è©³ç´°æ•¸æ“šåˆ†æ")
                st.dataframe(pd.DataFrame(info_list), use_container_width=True)
