import streamlit as st
import cv2
import numpy as np
import os
import time
import av
import joblib
from streamlit_drawable_canvas import st_canvas
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, WebRtcMode
from streamlit_image_coordinates import streamlit_image_coordinates
from tensorflow.keras.models import load_model
from tensorflow.keras.datasets import mnist
from sklearn.neighbors import KNeighborsClassifier

# è¨­å®šé é¢
st.set_page_config(page_title="AI æ‰‹å¯«è¾¨è­˜ (Guide Ver.)", page_icon="ğŸ”¢", layout="wide")
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# ==========================================
# 1. å…±ç”¨æ ¸å¿ƒ
# ==========================================
@st.cache_resource
def load_models():
    # 1. è¼‰å…¥ CNN (ä¸»æ¨¡å‹)
    cnn = None
    model_files = ["cnn_model_robust.h5", "mnist_cnn.h5", "cnn_model.h5"]
    for f in model_files:
        if os.path.exists(f):
            try:
                cnn = load_model(f)
                print(f"âœ… CNN æ¨¡å‹è¼‰å…¥æˆåŠŸ: {f}")
                break
            except: pass
    
    # 2. è¼‰å…¥æˆ–è¨“ç·´ KNN (è¼”åŠ©æ¨¡å‹)
    knn = None
    knn_path = "knn_model.pkl"
    if os.path.exists(knn_path):
        try:
            knn = joblib.load(knn_path)
            print("âœ… KNN æ¨¡å‹è¼‰å…¥æˆåŠŸ")
        except: pass
    
    if knn is None:
        st.toast("æ­£åœ¨è¨“ç·´è¼”åŠ©ç”¨ KNN æ¨¡å‹ (åˆæ¬¡åŸ·è¡Œè¼ƒæ…¢)...")
        try:
            (x_train, y_train), _ = mnist.load_data()
            x_flat = x_train.reshape(-1, 784) / 255.0
            knn = KNeighborsClassifier(n_neighbors=5)
            knn.fit(x_flat[:10000], y_train[:10000])
            joblib.dump(knn, knn_path)
            print("âœ… KNN æ¨¡å‹è¨“ç·´å®Œæˆ")
        except: pass
        
    return cnn, knn

cnn_model, knn_model = load_models()

def v65_morphology(binary_img, erosion, dilation):
    res = binary_img.copy()
    kernel_noise = np.ones((2,2), np.uint8)
    res = cv2.morphologyEx(res, cv2.MORPH_OPEN, kernel_noise)

    if erosion > 0:
        kernel = np.ones((3,3), np.uint8)
        res = cv2.erode(res, kernel, iterations=erosion)
    
    kernel_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    res = cv2.morphologyEx(res, cv2.MORPH_CLOSE, kernel_rect, iterations=1)
    
    if dilation > 0:
        res = cv2.dilate(res, None, iterations=dilation)
    return res

def center_by_moments(img):
    m = cv2.moments(img, True)
    if m['m00'] < 0.1: return cv2.resize(img, (28, 28))
    cX, cY = m['m10'] / m['m00'], m['m01'] / m['m00']
    tX, tY = 14.0 - cX, 14.0 - cY
    M = np.float32([[1, 0, tX], [0, 1, tY]])
    return cv2.warpAffine(img, M, (28, 28), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT, borderValue=0)

def preprocess_input(roi):
    h, w = roi.shape
    scale = 20.0 / max(h, w)
    nh, nw = max(1, int(h * scale)), max(1, int(w * scale))
    resized = cv2.resize(roi, (nw, nh), interpolation=cv2.INTER_AREA)
    canvas = np.zeros((28, 28), dtype=np.uint8)
    y_off, x_off = (28 - nh) // 2, (28 - nw) // 2
    canvas[y_off:y_off+nh, x_off:x_off+nw] = resized
    final = center_by_moments(canvas)
    cnn_in = final.reshape(1, 28, 28, 1).astype('float32') / 255.0
    knn_in = final.reshape(1, 784).astype('float32') / 255.0
    return cnn_in, knn_in

def count_holes(binary_roi):
    contours, hierarchy = cv2.findContours(binary_roi, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    holes = 0
    if hierarchy is not None:
        for h in hierarchy[0]:
            if h[3] != -1:
                holes += 1
    return holes

def check_multiline_complexity(binary_roi):
    h, w = binary_roi.shape
    max_strokes = 0
    for r_ratio in [0.25, 0.5, 0.75]:
        row = binary_roi[int(h * r_ratio), :] / 255
        transitions = np.sum(np.abs(np.diff(row)))
        strokes = (transitions + 1) // 2
        max_strokes = max(max_strokes, strokes)
    for c_ratio in [0.25, 0.5, 0.75]:
        col = binary_roi[:, int(w * c_ratio)] / 255
        transitions = np.sum(np.abs(np.diff(col)))
        strokes = (transitions + 1) // 2
        max_strokes = max(max_strokes, strokes)
    return max_strokes

def draw_label(img, text, x, y, color=(0, 255, 255)):
    font = cv2.FONT_HERSHEY_SIMPLEX
    scale = 0.8
    thickness = 2
    (lw, lh), _ = cv2.getTextSize(text, font, scale, thickness)
    cv2.rectangle(img, (x, y - lh - 10), (x + lw, y), (0, 0, 0), -1)
    cv2.putText(img, text, (x, y - 5), font, scale, color, thickness)

# ==========================================
# 2. é¡é ­æ¨¡å¼
# ==========================================
class LiveProcessor(VideoProcessorBase):
    def __init__(self):
        self.model = cnn_model
        self.knn = knn_model
        self.erosion = 0
        self.dilation = 2
        self.min_conf = 0.6
        self.frozen = False
        self.frozen_frame = None
        
    def update_params(self, ero, dil, conf):
        self.erosion = ero
        self.dilation = dil
        self.min_conf = conf

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")
        if self.frozen and self.frozen_frame is not None:
             return av.VideoFrame.from_ndarray(self.frozen_frame, format="bgr24")

        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        blur = cv2.GaussianBlur(gray, (5, 5), 0)
        binary = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 19, 10)
        binary_proc = v65_morphology(binary, self.erosion, self.dilation)
        
        cnts, _ = cv2.findContours(binary_proc, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        boxes_data = []
        for c in cnts:
            if cv2.contourArea(c) < 100: continue
            x, y, w, h = cv2.boundingRect(c)
            if x<5 or y<5: continue
            boxes_data.append((x,y,w,h))
        
        boxes_data.sort(key=lambda b: b[0])

        count_id = 1
        for (x, y, w, h) in boxes_data:
            roi = binary_proc[y:y+h, x:x+w]
            cnn_in, _ = preprocess_input(roi)
            if self.model:
                pred = self.model.predict(cnn_in, verbose=0)[0]
                conf = np.max(pred)
                lbl = np.argmax(pred)
                
                if conf > self.min_conf:
                    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)
                    draw_label(img, f"#{count_id}", x, y)
                    count_id += 1

        return av.VideoFrame.from_ndarray(img, format="bgr24")

def run_camera_mode(erosion, dilation, min_conf):
    # [æ–°å¢] è©³ç´°ä½¿ç”¨èªªæ˜
    with st.expander("ğŸ“– é¡é ­æ¨¡å¼ä½¿ç”¨æŒ‡å— & æ³¨æ„äº‹é … (é»æ“Šå±•é–‹)", expanded=True):
        st.markdown("""
        ### ğŸ¯ ä½¿ç”¨æ­¥é©Ÿ
        1. **å•Ÿå‹•**ï¼šé»æ“Šä¸‹æ–¹ `START` æŒ‰éˆ•ï¼Œç€è¦½å™¨æœƒè«‹æ±‚æ”å½±æ©Ÿæ¬Šé™ï¼Œè«‹é»é¸ã€Œå…è¨±ã€ã€‚
        2. **å°æº–**ï¼šå°‡å¯«æœ‰æ•¸å­—çš„ç´™å¼µæˆ–ç‰©é«”ï¼Œå¹³ç©©åœ°ç½®æ–¼ç•«é¢ä¸­å¤®ã€‚
        3. **åˆ¤è®€**ï¼šç³»çµ±æœƒå³æ™‚æ¡†é¸çœ‹åˆ°çš„æ•¸å­—ï¼Œä¸¦é¡¯ç¤ºç¶ è‰²æ¡†æ¡†èˆ‡ç·¨è™Ÿã€‚

        ### âš ï¸ æ³¨æ„äº‹é …èˆ‡æŠ€å·§
        * **ğŸ’¡ å…‰ç·šæ˜¯é—œéµ**ï¼šè«‹ç¢ºä¿ç’°å¢ƒ**å…‰ç·šå……è¶³**ã€‚å¤ªæš—æˆ–æœ‰å¼·çƒˆé™°å½±ï¼ˆä¾‹å¦‚æ‰‹æ©Ÿé®ä½å…‰ç·šï¼‰æœƒå°è‡´èª¤åˆ¤ã€‚
        * **ğŸ’¡ èƒŒæ™¯è¦ä¹¾æ·¨**ï¼šæœ€ç†æƒ³çš„æƒ…æ³æ˜¯ **ã€Œç™½ç´™é»‘å­—ã€**ã€‚å¦‚æœèƒŒæ™¯å¤ªé›œäº‚ï¼ˆä¾‹å¦‚æœ‰æ ¼å­ã€èŠ±ç´‹ï¼‰ï¼Œç³»çµ±å¯èƒ½æœƒæ··æ·†ã€‚
        * **ğŸ’¡ è·é›¢è¦é©ä¸­**ï¼šæ•¸å­—å¤ªå°ï¼ˆé›¢é¡é ­å¤ªé ï¼‰æœƒçœ‹ä¸æ¸…æ¥šï¼›æ•¸å­—å¤ªå¤§ï¼ˆçˆ†æ¡†ï¼‰ä¹Ÿæœƒç„¡æ³•è¾¨è­˜ã€‚
        * **ğŸ’¡ é¿å…æ‰‹éœ‡**ï¼šæ‰‹æŒé¡é ­æ™‚è«‹ç›¡é‡ä¿æŒç©©å®šï¼Œæ¨¡ç³Šçš„å½±åƒæœƒè®“ AI çœ‹æˆä¸€åœ˜éœ§ã€‚
        """)

    st.info("ğŸ“· é¡é ­æ¨¡å¼ (ç‚ºæ±‚æµæš¢ï¼Œæ­¤æ¨¡å¼ä¸»è¦ä½¿ç”¨ CNN)")
    ctx = webrtc_streamer(
        key="v65-cam",
        mode=WebRtcMode.SENDRECV,
        video_processor_factory=LiveProcessor,
        async_processing=True,
    )
    if ctx.video_processor:
        ctx.video_processor.update_params(erosion, dilation, min_conf)

# ==========================================
# 3. æ‰‹å¯«æ¿æ¨¡å¼
# ==========================================
def run_canvas_mode(erosion, dilation, min_conf):
    # [æ–°å¢] è©³ç´°ä½¿ç”¨èªªæ˜
    with st.expander("ğŸ“– æ‰‹å¯«æ¿æ¨¡å¼ä½¿ç”¨æŒ‡å— & æ³¨æ„äº‹é … (é»æ“Šå±•é–‹)", expanded=True):
        st.markdown("""
        ### ğŸ¯ ä½¿ç”¨æ­¥é©Ÿ
        1. **æ›¸å¯«**ï¼šåœ¨ä¸‹æ–¹çš„é»‘è‰²ç•«å¸ƒå€ï¼Œç”¨æ»‘é¼ æˆ–è§¸æ§ç­†ç›´æ¥å¯«ä¸‹ 0-9 çš„æ•¸å­—ã€‚
        2. **å·¥å…·**ï¼š
            * **âœï¸ ç•«ç­†**ï¼šé è¨­å·¥å…·ï¼Œç”¨ä¾†å¯«å­—ã€‚
            * **ğŸ§½ æ©¡çš®æ“¦**ï¼šæ“¦æ‰å¯«éŒ¯çš„éƒ¨åˆ†ã€‚
            * **â†©ï¸ å¾©åŸä¸€ç­†**ï¼šå¯«å£äº†ï¼ŸæŒ‰ä¸€ä¸‹ç¨å¾®å›æº¯ï¼Œä¸ç”¨å…¨éƒ¨é‡å¯«ã€‚
            * **ğŸ—‘ï¸ æ¸…é™¤å…¨éƒ¨**ï¼šä¸€éµæ¸…ç©ºç•«å¸ƒï¼Œé‡æ–°é–‹å§‹ã€‚
        
        ### âš ï¸ æ³¨æ„äº‹é …èˆ‡æŠ€å·§
        * **ğŸ’¡ å­—é«”ç«¯æ­£**ï¼šé›–ç„¶ AI çœ‹å¾—æ‡‚æ½¦è‰å­—ï¼Œä½†å¯«å¾—ç«¯æ­£æº–ç¢ºåº¦æœ€é«˜ã€‚
        * **ğŸ’¡ ä¸è¦é»åœ¨ä¸€èµ·**ï¼šè«‹å°‡æ¯å€‹æ•¸å­—åˆ†é–‹å¯«ï¼Œ**ä¸è¦é€£ç­†**æˆ–é‡ç–Šï¼Œå¦å‰‡ AI æœƒæŠŠå®ƒå€‘çœ‹æˆåŒä¸€å€‹å¥‡æ€ªçš„ç¬¦è™Ÿã€‚
        * **ğŸ’¡ ç­†åŠƒå®Œæ•´**ï¼šä¾‹å¦‚æ•¸å­— `0` æˆ– `8`ï¼Œè«‹ç›¡é‡æŠŠåœˆåœˆå°å¥½ï¼Œä¸è¦ç•™å¤ªå¤§çš„ç¼ºå£ã€‚
        """)

    if 'canvas_json' not in st.session_state: st.session_state['canvas_json'] = None
    if 'initial_drawing' not in st.session_state: st.session_state['initial_drawing'] = None

    c1, c2 = st.columns([3, 1.5])
    
    with c1:
        st.markdown("### âœï¸ è«‹åœ¨æ­¤æ›¸å¯«")
        c_tool, c_acts = st.columns([1.5, 2])
        with c_tool:
            tool_mode = st.radio("ğŸ–Šï¸ å·¥å…·", ["âœï¸ ç•«ç­†", "ğŸ§½ æ©¡çš®æ“¦"], horizontal=True, label_visibility="collapsed")
        
        with c_acts:
            b_undo, b_clear = st.columns(2)
            with b_undo:
                if st.button("â†©ï¸ å¾©åŸä¸€ç­†", use_container_width=True):
                    if st.session_state['canvas_json'] is not None:
                        data = st.session_state['canvas_json']
                        if "objects" in data and len(data["objects"]) > 0:
                            data["objects"].pop()
                            st.session_state['initial_drawing'] = data
                            st.session_state['canvas_key'] = f"canvas_{time.time()}"
                            st.rerun()
            with b_clear:
                if st.button("ğŸ—‘ï¸ æ¸…é™¤å…¨éƒ¨", use_container_width=True):
                    st.session_state['canvas_key'] = f"canvas_{time.time()}"
                    st.session_state['initial_drawing'] = None
                    st.rerun()

        canvas_res = st_canvas(
            fill_color="rgba(255, 165, 0, 0.3)",
            stroke_width=15 if tool_mode == "âœï¸ ç•«ç­†" else 40,
            stroke_color="#FFFFFF" if tool_mode == "âœï¸ ç•«ç­†" else "#000000",
            background_color="#000000",
            height=400, width=650, drawing_mode="freedraw",
            initial_drawing=st.session_state['initial_drawing'],
            key=st.session_state.get('canvas_key', 'canvas_0'),
            display_toolbar=True
        )
        if canvas_res.json_data is not None: st.session_state['canvas_json'] = canvas_res.json_data
    
    with c2:
        st.markdown("### ğŸ“Š è¾¨è­˜æ¸…å–®")
        result_container = st.container(height=400, border=True)
        
        if canvas_res.image_data is not None and np.max(canvas_res.image_data) > 0:
            raw = canvas_res.image_data.astype(np.uint8)
            img_bgr = cv2.cvtColor(raw, cv2.COLOR_RGBA2BGR) if raw.shape[2] == 4 else raw
            gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
            _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            processed = v65_morphology(binary, erosion, dilation)
            
            with st.expander("ğŸ‘ï¸ Debug (AI è¦–è§’)"):
                st.image(processed, caption="äºŒå€¼åŒ–å½±åƒ", use_container_width=True)
            
            cnts, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            boxes = sorted([cv2.boundingRect(c) for c in cnts if cv2.contourArea(c) > 50], key=lambda b: b[0])
            draw_img = img_bgr.copy()
            results_list = []
            
            for i, (x, y, w, h) in enumerate(boxes):
                roi = processed[y:y+h, x:x+w]
                cnn_in, _ = preprocess_input(roi)
                
                pred = cnn_model.predict(cnn_in, verbose=0)[0]
                conf = np.max(pred)
                lbl = np.argmax(pred)
                
                if conf > min_conf:
                    cv2.rectangle(draw_img, (x, y), (x+w, y+h), (0, 255, 0), 2)
                    draw_label(draw_img, f"#{i+1}", x, y)
                    results_list.append({"ç·¨è™Ÿ": f"#{i+1}", "é æ¸¬æ•¸å­—": str(lbl), "ä¿¡å¿ƒåº¦": f"{int(conf*100)}%"})
            
            with result_container:
                if results_list: st.dataframe(results_list, hide_index=True, use_container_width=True)
                else: st.info("å°šæœªåµæ¸¬åˆ°æ•¸å­—")
        else:
            with result_container: st.info("è«‹åœ¨å·¦å´æ›¸å¯«...")

# ==========================================
# 4. ä¸Šå‚³æ¨¡å¼ (æ•´åˆ CNN + KNN é›™é‡é©—è­‰)
# ==========================================
def run_upload_mode(erosion, dilation, min_conf):
    # [æ–°å¢] è©³ç´°ä½¿ç”¨èªªæ˜
    with st.expander("ğŸ“– ä¸Šå‚³æ¨¡å¼ä½¿ç”¨æŒ‡å— & ç–‘é›£æ’è§£ (é»æ“Šå±•é–‹)", expanded=True):
        st.markdown("""
        ### ğŸ¯ ä½¿ç”¨æ­¥é©Ÿ
        1. **ä¸Šå‚³**ï¼šé»æ“Š `Browse files` é¸æ“‡ä¸€å¼µå«æœ‰æ•¸å­—çš„åœ–ç‰‡ (JPG/PNG)ã€‚
        2. **ç­‰å¾…**ï¼šç³»çµ±æœƒè‡ªå‹•é€²è¡Œå½±åƒè™•ç†ã€åˆ‡å‰²ã€èˆ‡é›™é‡æ¨¡å‹é©—è­‰ã€‚
        3. **æª¢è¦–**ï¼šåœ–ç‰‡ä¸Šæœƒé¡¯ç¤ºç¶ è‰²æ¡†èˆ‡ç·¨è™Ÿï¼Œå³å´æ¸…å–®æœƒåˆ—å‡ºè©³ç´°çµæœã€‚

        ### âš ï¸ ç‚ºä»€éº¼æœ‰äº›å­—æ²’æŠ“åˆ°ï¼Ÿ(ç³»çµ±éæ¿¾æ©Ÿåˆ¶)
        ç‚ºäº†é¿å…æŠŠã€Œåœ‹å­—ã€ã€ã€Œæ’åœ–ã€æˆ–ã€Œé™°å½±ã€èª¤åˆ¤æˆæ•¸å­—ï¼Œæœ¬æ¨¡å¼å•Ÿç”¨äº† **åš´æ ¼éæ¿¾**ï¼š
        * **ğŸš« å½¢ç‹€ä¸å°**ï¼šå¦‚æœæ¡†æ¡†å¤ªç´°é•·ï¼ˆåƒ "l"ï¼‰æˆ–å¤ªå¯¬æ‰ï¼ˆåƒ "ä¸€"ï¼‰ï¼Œæœƒè¢«è¦–ç‚ºé›œè¨Šã€‚
        * **ğŸš« çµæ§‹å¤ªè¤‡é›œ**ï¼šç³»çµ±æœƒæƒæç­†ç•«ï¼Œå¦‚æœç™¼ç¾ç·šæ¢ç¸±æ©«äº¤éŒ¯ï¼ˆåƒã€Œæ³•ã€ã€ã€Œå‰‡ã€ç­‰ä¸­æ–‡å­—ï¼‰ï¼Œæœƒç›´æ¥å¿½ç•¥ã€‚
        * **ğŸš« å¯†åº¦ç•°å¸¸**ï¼šå¦‚æœä¸€å€‹æ¡†æ¡†è£¡é»‘è‰²å¡«æ»¿çš„æ¯”ä¾‹å¤ªé«˜ï¼ˆåƒå¯¦å¿ƒæ–¹å¡Šï¼‰æˆ–å¤ªä½ï¼ˆåƒç©ºå¿ƒåœ“åœˆï¼‰ï¼Œä¹Ÿæœƒè¢«éæ¿¾ã€‚
        * **ğŸš« é›™é‡é©—è­‰å¤±æ•—**ï¼šå¦‚æœ **CNN** æ¨¡å‹èªªæ˜¯ 8ï¼Œä½† **KNN** æ¨¡å‹èªªæ˜¯ 6ï¼Œç³»çµ±æœƒåˆ¤å®šç‚ºã€Œæœ‰çˆ­è­°ã€ä¸¦æ‰£åˆ†ï¼Œä¿¡å¿ƒä¸è¶³å°±æœƒéš±è—ã€‚

        ### ğŸ’¡ æå‡æº–ç¢ºç‡çš„å°æ’‡æ­¥
        * ç›¡é‡ä½¿ç”¨ **ç™½åº•é»‘å­—** çš„åœ–ç‰‡ã€‚
        * å¦‚æœå­—é»åœ¨ä¸€èµ·ï¼Œè©¦è‘—èª¿æ•´å·¦å´çš„ **ã€Œåˆ‡å‰²æ²¾é» (Erosion)ã€** åƒæ•¸ã€‚
        * å¦‚æœå­—ç­†ç•«æ–·æ‰ï¼Œè©¦è‘—èª¿æ•´å·¦å´çš„ **ã€Œç­†ç•«åŠ ç²— (Dilation)ã€** åƒæ•¸ã€‚
        """)

    st.info("âœ… å·²å•Ÿç”¨ã€é›™é‡æ¨¡å‹é©—è­‰ã€‘+ã€çµæ§‹è¤‡é›œåº¦éæ¿¾ã€‘ï¼Œå¼·åŠ›æ’é™¤éæ•¸å­—å¹²æ“¾")
    
    file = st.file_uploader("é¸æ“‡åœ–ç‰‡", type=["jpg", "png", "jpeg"])
    
    if file:
        file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
        img_origin = cv2.imdecode(file_bytes, 1)
        h_orig, w_orig = img_origin.shape[:2]
        gray = cv2.cvtColor(img_origin, cv2.COLOR_BGR2GRAY)
        
        thresh_adapt = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 35, 15)
        _, thresh_otsu = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        binary_combined = cv2.bitwise_and(thresh_adapt, thresh_otsu)
        processed = v65_morphology(binary_combined, erosion, dilation)
        
        cnts, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        detected_count = 0
        display_img = img_origin.copy()
        valid_boxes_data = []
        
        for c in cnts:
            area = cv2.contourArea(c)
            if area < 100: continue 
            x, y, w, h = cv2.boundingRect(c)
            
            # ç‰©ç†éæ¿¾
            if x < 10 or y < 10 or (x+w) > w_orig-10 or (y+h) > h_orig-10: continue
            if w * h > (h_orig * w_orig * 0.15): continue
            
            roi_check = processed[y:y+h, x:x+w]
            density = cv2.countNonZero(roi_check) / (w * h)
            if density < 0.15 or density > 0.55: continue 
            
            aspect_ratio = w / float(h)
            if aspect_ratio > 1.2: continue 
            if aspect_ratio < 0.15: continue
            
            max_strokes = check_multiline_complexity(roi_check)
            if max_strokes > 3: continue 
            
            # é›™é‡æ¨¡å‹é æ¸¬
            roi = processed[y:y+h, x:x+w]
            cnn_in, knn_in = preprocess_input(roi)
            
            pred_cnn = cnn_model.predict(cnn_in, verbose=0)[0]
            conf_cnn = np.max(pred_cnn)
            lbl_cnn = np.argmax(pred_cnn)
            
            lbl_knn = -1
            if knn_model:
                lbl_knn = knn_model.predict(knn_in)[0]
            
            final_conf = conf_cnn
            is_disagree = False
            
            if knn_model and lbl_cnn != lbl_knn:
                final_conf -= 0.30 
                is_disagree = True
            
            holes = count_holes(roi)
            if lbl_cnn != 1 and aspect_ratio < 0.35: continue
            if lbl_cnn == 1 and aspect_ratio > 0.6: continue
            if lbl_cnn in [8, 0, 6, 9] and holes == 0: continue
            if lbl_cnn in [1, 2, 3, 5, 7] and holes > 0: continue

            target_thresh = min_conf
            if lbl_cnn in [4, 7]: target_thresh += 0.20
            
            if final_conf > target_thresh:
                status_note = ""
                if is_disagree: status_note = " (âš ï¸çˆ­è­°)"
                
                valid_boxes_data.append({
                    'rect': (x, y, w, h),
                    'lbl': lbl_cnn,
                    'conf': final_conf,
                    'note': status_note
                })

        valid_boxes_data.sort(key=lambda item: (item['rect'][1]//50, item['rect'][0]))
        results_list = []

        for idx, item in enumerate(valid_boxes_data):
            x, y, w, h = item['rect']
            lbl = item['lbl']
            conf = item['conf']
            
            cv2.rectangle(display_img, (x,y), (x+w,y+h), (0,255,0), 2)
            draw_label(display_img, f"#{idx+1}", x, y)
            results_list.append(f"**#{idx+1}**: æ•¸å­— `{lbl}` ({int(conf*100)}%){item['note']}")
            detected_count += 1

        img_rgb = cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB)
        c1, c2 = st.columns([3, 1])
        with c1:
            st.image(img_rgb, use_container_width=True, caption="è¾¨è­˜çµæœ (åƒ…ç·¨è™Ÿ)")
        with c2:
            st.image(processed, use_container_width=True, caption="[Debug] AI è¦–è§’")
            st.markdown(f"**å…±æ‰¾åˆ° {detected_count} å€‹æ•¸å­—**")
            if results_list:
                st.markdown("---")
                st.markdown("#### ğŸ“ è©³ç´°æ¸…å–®")
                for r in results_list: st.markdown(r)

# ==========================================
# 5. ä¸»ç¨‹å¼åˆ†æµ
# ==========================================
def main():
    st.sidebar.title("ğŸ”¢ æ‰‹å¯«è¾¨è­˜ (Guide Ver.)")
    mode = st.sidebar.radio("é¸æ“‡æ¨¡å¼", ["ğŸ“· é¡é ­ (Live)", "âœï¸ æ‰‹å¯«æ¿ (Canvas)", "ğŸ“‚ ä¸Šå‚³åœ–ç‰‡ (Upload)"])
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸ”ª V65 æ‰‹è¡“åˆ€åƒæ•¸")
    
    # è©³ç´°çš„åƒæ•¸èª¿æ•´æŒ‡å—
    with st.sidebar.expander("â“ åƒæ•¸èª¿æ•´æŒ‡å—"):
        st.markdown("""
        **1. åˆ‡å‰²æ²¾é» (Erosion)**
        * **åŠŸèƒ½**ï¼šæŠŠè®Šç²—çš„ç·šæ¢ã€Œå‰Šç´°ã€ã€‚
        * **ä½•æ™‚ç”¨**ï¼šç•¶å…©å€‹æ•¸å­—é å¤ªè¿‘ï¼Œè¢«æ¡†åœ¨åŒä¸€å€‹æ¡†æ¡†æ™‚ï¼Œ**èª¿å¤§**æ­¤æ•¸å€¼ã€‚
        
        **2. ç­†ç•«åŠ ç²— (Dilation)**
        * **åŠŸèƒ½**ï¼šæŠŠè®Šç´°çš„ç·šæ¢ã€Œè®Šç²—ã€ã€‚
        * **ä½•æ™‚ç”¨**ï¼šç•¶ä¸€å€‹æ•¸å­—æ–·æˆå…©æˆª (ä¾‹å¦‚ 5 çš„ä¸Šé¢æ–·æ‰)ï¼Œè¢«èªæˆå…©å€‹å­—æ™‚ï¼Œ**èª¿å¤§**æ­¤æ•¸å€¼ã€‚
        
        **3. ä¿¡å¿ƒé–€æª»**
        * **åŠŸèƒ½**ï¼šAI å¤šæœ‰æŠŠæ¡æ‰æ•¢é¡¯ç¤ºå‡ºä¾†ã€‚
        * **ä½•æ™‚ç”¨**ï¼šç•«é¢é›œè¨Šå¤ªå¤šã€å‡ºç¾å¾ˆå¤šèª¤åˆ¤æ™‚ï¼Œ**èª¿é«˜**æ­¤å€¼ï¼›å­—éƒ½æŠ“ä¸åˆ°æ™‚ï¼Œ**èª¿ä½**æ­¤å€¼ã€‚
        """)

    erosion_iter = st.sidebar.slider("åˆ‡å‰²æ²¾é» (Erosion)", 0, 5, 0)
    dilation_iter = st.sidebar.slider("ç­†ç•«åŠ ç²— (Dilation)", 0, 3, 2)
    min_conf = st.sidebar.slider("ä¿¡å¿ƒé–€æª»", 0.0, 1.0, 0.80) 

    if cnn_model is None:
        st.error("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ")
        st.stop()

    if mode == "ğŸ“· é¡é ­ (Live)":
        run_camera_mode(erosion_iter, dilation_iter, min_conf)
    elif mode == "âœï¸ æ‰‹å¯«æ¿ (Canvas)":
        run_canvas_mode(erosion_iter, dilation_iter, min_conf)
    elif mode == "ğŸ“‚ ä¸Šå‚³åœ–ç‰‡ (Upload)":
        run_upload_mode(erosion_iter, dilation_iter, min_conf)

if __name__ == "__main__":
    main()
